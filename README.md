# Multi-Provider LLM Integration Lab

Este reposit√≥rio cont√©m implementa√ß√µes t√©cnicas para integra√ß√£o com Large Language Models (LLMs) utilizando o **Google Gemini SDK** e a **API do OpenRouter**. O foco deste projeto √© demonstrar o gerenciamento manual de contexto e a persist√™ncia de cadeias de racioc√≠nio (*Chain-of-Thought*).

## üõ†Ô∏è Arquitetura e Implementa√ß√£o

O projeto explora duas abordagens distintas de comunica√ß√£o com modelos de linguagem:

### 1. Google GenAI (Nativo)
Utiliza o modelo `gemini-2.5-flash` focado em conversa√ß√£o cont√≠nua.
- **Gerenciamento de Estado:** O c√≥digo alterna IDs de intera√ß√£o (`previous_interaction_id`) para garantir que o hist√≥rico da conversa seja mantido sem a necessidade de reenviar todo o hist√≥rico de mensagens manualmente.
- **Configura√ß√£o de Infer√™ncia:** - `thinking_level: "high"`: Habilita o processamento anal√≠tico profundo.
  - `temperature: 0.65`: Configurado para equilibrar precis√£o t√©cnica com fluidez na resposta.

### 2. OpenRouter (REST API)
Utiliza o modelo `xiaomi/mimo-v2-flash:free` para demonstrar a manipula√ß√£o de metadados de racioc√≠nio.
- **Reasoning Persistence:** Captura o campo `reasoning_details` da resposta da IA.
- **Loop de Valida√ß√£o:** O script injeta o racioc√≠nio anterior de volta na pr√≥xima requisi√ß√£o, permitindo que o modelo realize autocr√≠tica e valide suas pr√≥prias conclus√µes l√≥gicas.

---

## üöÄ Como Configurar

1. **Instale as depend√™ncias:**
   ```bash
   pip install -U google-genai requests